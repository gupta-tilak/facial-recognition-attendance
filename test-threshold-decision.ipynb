{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "csv_path = '/Users/guptatilak/Documents/C4GT-Face-Recognition/Dataset/An Indian facial database highlighting the Spectacle 2/Version 2/test_combinations_without_specs.csv'\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "data=data.sample(500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_data=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=tmp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img1_path</th>\n",
       "      <th>img2_path</th>\n",
       "      <th>truth_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>/Users/guptatilak/Documents/C4GT-Face-Recognit...</td>\n",
       "      <td>/Users/guptatilak/Documents/C4GT-Face-Recognit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3664</th>\n",
       "      <td>/Users/guptatilak/Documents/C4GT-Face-Recognit...</td>\n",
       "      <td>/Users/guptatilak/Documents/C4GT-Face-Recognit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>/Users/guptatilak/Documents/C4GT-Face-Recognit...</td>\n",
       "      <td>/Users/guptatilak/Documents/C4GT-Face-Recognit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>/Users/guptatilak/Documents/C4GT-Face-Recognit...</td>\n",
       "      <td>/Users/guptatilak/Documents/C4GT-Face-Recognit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3685</th>\n",
       "      <td>/Users/guptatilak/Documents/C4GT-Face-Recognit...</td>\n",
       "      <td>/Users/guptatilak/Documents/C4GT-Face-Recognit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4328</th>\n",
       "      <td>/Users/guptatilak/Documents/C4GT-Face-Recognit...</td>\n",
       "      <td>/Users/guptatilak/Documents/C4GT-Face-Recognit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4480</th>\n",
       "      <td>/Users/guptatilak/Documents/C4GT-Face-Recognit...</td>\n",
       "      <td>/Users/guptatilak/Documents/C4GT-Face-Recognit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>/Users/guptatilak/Documents/C4GT-Face-Recognit...</td>\n",
       "      <td>/Users/guptatilak/Documents/C4GT-Face-Recognit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>/Users/guptatilak/Documents/C4GT-Face-Recognit...</td>\n",
       "      <td>/Users/guptatilak/Documents/C4GT-Face-Recognit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3679</th>\n",
       "      <td>/Users/guptatilak/Documents/C4GT-Face-Recognit...</td>\n",
       "      <td>/Users/guptatilak/Documents/C4GT-Face-Recognit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              img1_path  \\\n",
       "2147  /Users/guptatilak/Documents/C4GT-Face-Recognit...   \n",
       "3664  /Users/guptatilak/Documents/C4GT-Face-Recognit...   \n",
       "2186  /Users/guptatilak/Documents/C4GT-Face-Recognit...   \n",
       "302   /Users/guptatilak/Documents/C4GT-Face-Recognit...   \n",
       "3685  /Users/guptatilak/Documents/C4GT-Face-Recognit...   \n",
       "...                                                 ...   \n",
       "4328  /Users/guptatilak/Documents/C4GT-Face-Recognit...   \n",
       "4480  /Users/guptatilak/Documents/C4GT-Face-Recognit...   \n",
       "1944  /Users/guptatilak/Documents/C4GT-Face-Recognit...   \n",
       "1176  /Users/guptatilak/Documents/C4GT-Face-Recognit...   \n",
       "3679  /Users/guptatilak/Documents/C4GT-Face-Recognit...   \n",
       "\n",
       "                                              img2_path  truth_value  \n",
       "2147  /Users/guptatilak/Documents/C4GT-Face-Recognit...            1  \n",
       "3664  /Users/guptatilak/Documents/C4GT-Face-Recognit...            0  \n",
       "2186  /Users/guptatilak/Documents/C4GT-Face-Recognit...            1  \n",
       "302   /Users/guptatilak/Documents/C4GT-Face-Recognit...            1  \n",
       "3685  /Users/guptatilak/Documents/C4GT-Face-Recognit...            0  \n",
       "...                                                 ...          ...  \n",
       "4328  /Users/guptatilak/Documents/C4GT-Face-Recognit...            0  \n",
       "4480  /Users/guptatilak/Documents/C4GT-Face-Recognit...            0  \n",
       "1944  /Users/guptatilak/Documents/C4GT-Face-Recognit...            1  \n",
       "1176  /Users/guptatilak/Documents/C4GT-Face-Recognit...            1  \n",
       "3679  /Users/guptatilak/Documents/C4GT-Face-Recognit...            0  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guptatilak/Documents/C4GT-Face-Recognition/offline-FR/faceboxes-edgeface-FR/embeddings.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
      "/Users/guptatilak/Documents/C4GT-Face-Recognition/offline-FR/faceboxes-edgeface-FR/detection.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from weights/FaceBoxes.pth\n",
      "remove prefix 'module.'\n",
      "Missing keys:27\n",
      "Unused checkpoint keys:0\n",
      "Used keys:147\n",
      "Loading pretrained model from weights/FaceBoxes.pth\n",
      "remove prefix 'module.'\n",
      "Missing keys:27\n",
      "Unused checkpoint keys:0\n",
      "Used keys:147\n",
      "Cosine Similarity: 0.6470\n"
     ]
    }
   ],
   "source": [
    "# example_usage.py\n",
    "\n",
    "from compare_images import compare_images\n",
    "\n",
    "# Define image paths\n",
    "image1_path = 'images/Aisvarrya_8.jpeg'\n",
    "image2_path = 'images/Rajath_14.jpg'\n",
    "\n",
    "try:\n",
    "    # Call the compare_images function from the imported module\n",
    "    similarity = compare_images(image1_path, image2_path)\n",
    "    print(f\"Cosine Similarity: {similarity:.4f}\")\n",
    "except ValueError as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check illumination in the image\n",
    "def check_illumination(filename):\n",
    "    im = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "    if im is None:\n",
    "        print(f'ERROR: Unable to load {filename}')\n",
    "    # Calculate mean brightness as percentage\n",
    "    meanpercent = np.mean(im) * 100 / 255\n",
    "\n",
    "    if meanpercent > 38:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "# Function to denoise an image using Gaussian Blur\n",
    "def denoise_image(image_path):\n",
    "    try:\n",
    "        # Read the image using OpenCV\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is not None:\n",
    "            # Apply Gaussian Blur to denoise the image\n",
    "            denoised_img = cv2.GaussianBlur(img, (3, 3), 0.5)\n",
    "            return denoised_img\n",
    "        else:\n",
    "            print(f\"Error reading image: {image_path}\")\n",
    "            return None\n",
    "    except (IOError, SyntaxError, ValueError) as e:\n",
    "        print(f\"Error processing image: {image_path} ({e})\")\n",
    "        return None  # You can log the error for further investigation\n",
    "\n",
    "\n",
    "detector_backend = 'faceboxes'\n",
    "model_name = 'edgeface'\n",
    "distance_metric = 'cosine'\n",
    "align = False\n",
    "\n",
    "alignment_text = \"aligned\" if align is True else \"unaligned\"\n",
    "task = f\"{model_name}_{detector_backend}_{distance_metric}_{alignment_text}\"\n",
    "output_file = f\"threshold/outputs/{task}.csv\"\n",
    "\n",
    "distances = []\n",
    "truth_values = []\n",
    "times = []\n",
    "time_gaussian = []\n",
    "\n",
    "# Test for the first 10 rows of the dataframe only\n",
    "for index, row in tqdm(data.head(500).iterrows(), total=500, desc=task):\n",
    "    img1_target = row['img1_path']\n",
    "    img2_target = row['img2_path']\n",
    "    truth_value = row['truth_value']\n",
    "\n",
    "    if check_illumination(img1_target) and check_illumination(img2_target):\n",
    "        start_gaussian_time = time.time()\n",
    "        # Denoise images before verification\n",
    "        denoised_img1 = denoise_image(img1_target)\n",
    "        denoised_img2 = denoise_image(img2_target)\n",
    "        end_gaussian_time = time.time()\n",
    "\n",
    "        if denoised_img1 is None or denoised_img2 is None:\n",
    "            continue  # Skip this pair if any image couldn't be processed\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # result = DeepFace.verify(\n",
    "        #     img1_path=denoised_img1,\n",
    "        #     img2_path=denoised_img2,\n",
    "        #     model_name=model_name,\n",
    "        #     detector_backend=detector_backend,\n",
    "        #     distance_metric=distance_metric,\n",
    "        #     align=align,\n",
    "        #     enforce_detection=False,\n",
    "        #     # expand_percentage=expand_percentage, # Uncomment and set this if needed\n",
    "        # )\n",
    "\n",
    "        result = compare_images(img1_target, img2_target)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        distance = result\n",
    "        distances.append(distance)\n",
    "        truth_values.append(truth_value)\n",
    "        times.append(end_time - start_time)  # Calculate the time taken and store it\n",
    "        time_gaussian.append(end_gaussian_time - start_gaussian_time) # Calculate the time taken and store it\n",
    "\n",
    "    # Calculate the average time taken per pair of images\n",
    "    avg_time_per_pair = sum(times) / len(times)\n",
    "    avg_time_per_pair_gaussian = sum(time_gaussian) / len(time_gaussian)\n",
    "    print(f\"Average time taken per pair of images for {task}: {avg_time_per_pair:.4f} seconds\")\n",
    "    print(f\"Average time taken per pair of images for Gaussian Blur: {avg_time_per_pair_gaussian:.4f} seconds\")\n",
    "\n",
    "\n",
    "    # -----------------------------------\n",
    "    df = pd.DataFrame(data.head(10)['truth_value'], columns=[\"actuals\"])\n",
    "    df['actuals'] = truth_values\n",
    "    df[\"distances\"] = distances\n",
    "    df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [[0 for _ in range(len(models))] for _ in range(len(detectors))]\n",
    "# base_df = pd.DataFrame(data, columns=models, index=detectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Add a dictionary to store thresholds\u001b[39;00m\n\u001b[1;32m      6\u001b[0m best_thresholds \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Add a dictionary to store thresholds\n",
    "best_thresholds = {}\n",
    "\n",
    "result=pd.DataFrame(columns=['model_name','detector_backend','distance_metric','alignment','threshold','accuracy'])\n",
    "\n",
    "configs = [\n",
    "    {\"detector_backend\": \"faceboxes\", \"model_name\": \"edgeface\", \"distance_metric\": \"cosine\", \"align\": False},\n",
    "]\n",
    "\n",
    "for config in configs:\n",
    "    detector_backend = config[\"detector_backend\"]\n",
    "    model_name = config[\"model_name\"]\n",
    "    distance_metric = config[\"distance_metric\"]\n",
    "    is_aligned = config[\"align\"]\n",
    "\n",
    "    current_df = base_df.copy()\n",
    "    \n",
    "    align = \"aligned\" if is_aligned else \"unaligned\"\n",
    "    if detector_backend == \"skip\" and is_aligned:\n",
    "        align = \"unaligned\"\n",
    "\n",
    "    source_file = f\"/Users/guptatilak/Documents/C4GT-Face-Recognition/offline-FR/faceboxes-edgeface-FR/threshold/outputs/{model_name}_{detector_backend}_{distance_metric}_{align}.csv\"\n",
    "    \n",
    "    if not os.path.exists(source_file):\n",
    "        print(f\"Source file {source_file} does not exist. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(source_file)\n",
    "    \n",
    "    positive_mean = df[(df[\"actuals\"] == True) | (df[\"actuals\"] == 1)][\"distances\"].mean()\n",
    "    negative_mean = df[(df[\"actuals\"] == False) | (df[\"actuals\"] == 0)][\"distances\"].mean()\n",
    "\n",
    "    distances = sorted(df[\"distances\"].values.tolist())\n",
    "\n",
    "    items = []\n",
    "    for i, distance in enumerate(distances):\n",
    "        if distance >= positive_mean and distance <= negative_mean:\n",
    "            sandbox_df = df.copy()\n",
    "            sandbox_df[\"predictions\"] = False\n",
    "            idx = sandbox_df[sandbox_df[\"distances\"] < distance].index\n",
    "            sandbox_df.loc[idx, \"predictions\"] = True\n",
    "\n",
    "            actuals = sandbox_df.actuals.values.tolist()\n",
    "            predictions = sandbox_df.predictions.values.tolist()\n",
    "            accuracy = 100 * accuracy_score(actuals, predictions)\n",
    "            items.append((distance, accuracy))\n",
    "\n",
    "    if items:\n",
    "        pivot_df = pd.DataFrame(items, columns=[\"distance\", \"accuracy\"])\n",
    "        pivot_df = pivot_df.sort_values(by=[\"accuracy\"], ascending=False)\n",
    "        threshold = pivot_df.iloc[0][\"distance\"]\n",
    "        accuracy = pivot_df.iloc[0][\"accuracy\"]\n",
    "\n",
    "        # Save the best threshold for the model combination\n",
    "        best_thresholds[(model_name, detector_backend)] = threshold\n",
    "\n",
    "        # Add the accuracy to the dataframe\n",
    "        current_df.at[detector_backend, model_name] = accuracy\n",
    "        print(f\"Best threshold for {model_name} with {detector_backend} and alignment {'TRUE' if align == 'aligned' else 'FALSE'} is {threshold} with accuracy {accuracy}\")\n",
    "        data_to_append = {'model_name': model_name,\n",
    "                  'detector_backend': detector_backend,\n",
    "                  'distance_metric':distance_metric,\n",
    "                  'alignment' : 'TRUE' if align == 'aligned' else 'FALSE',\n",
    "                  'threshold': threshold,\n",
    "                  'accuracy': accuracy}\n",
    "\n",
    "        result = result.append(data_to_append, ignore_index=True)\n",
    "    else:\n",
    "        print(f\"No valid distances for {model_name} with {detector_backend}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source file /Users/guptatilak/Documents/C4GT-Face-Recognition/Testing/outputs/test/Dlib_yolov8_cosine_aligned.csv does not exist. Skipping...\n",
      "Threshold for Dlib with retinaface and alignment TRUE is 0.06 with accuracy 94.86458865610629\n",
      "Source file /Users/guptatilak/Documents/C4GT-Face-Recognition/Testing/outputs/test/GhostFaceNet_yolov8_cosine_aligned.csv does not exist. Skipping...\n",
      "Source file /Users/guptatilak/Documents/C4GT-Face-Recognition/Testing/outputs/test/GhostFaceNet_retinaface_cosine_aligned.csv does not exist. Skipping...\n",
      "  model_name detector_backend distance_metric alignment threshold   accuracy\n",
      "0       Dlib       retinaface          cosine      TRUE      0.06  94.864589\n"
     ]
    }
   ],
   "source": [
    "#using custom thresholds\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Dictionary to store the custom thresholds for each model combination\n",
    "custom_thresholds = {\n",
    "    (\"Dlib\", \"retinaface\"): 0.06,\n",
    "}\n",
    "\n",
    "result = pd.DataFrame(columns=['model_name', 'detector_backend', 'distance_metric', 'alignment', 'threshold', 'accuracy'])\n",
    "\n",
    "configs = [\n",
    "    {\"detector_backend\": \"yolov8\", \"model_name\": \"Dlib\", \"distance_metric\": \"cosine\", \"align\": True},\n",
    "    {\"detector_backend\": \"retinaface\", \"model_name\": \"Dlib\", \"distance_metric\": \"cosine\", \"align\": True},\n",
    "    {\"detector_backend\": \"yolov8\", \"model_name\": \"GhostFaceNet\", \"distance_metric\": \"cosine\", \"align\": True},\n",
    "    {\"detector_backend\": \"retinaface\", \"model_name\": \"GhostFaceNet\", \"distance_metric\": \"cosine\", \"align\": True}\n",
    "]\n",
    "\n",
    "for config in configs:\n",
    "    detector_backend = config[\"detector_backend\"]\n",
    "    model_name = config[\"model_name\"]\n",
    "    distance_metric = config[\"distance_metric\"]\n",
    "    is_aligned = config[\"align\"]\n",
    "\n",
    "    align = \"aligned\" if is_aligned else \"unaligned\"\n",
    "    if detector_backend == \"skip\" and is_aligned:\n",
    "        align = \"unaligned\"\n",
    "\n",
    "    source_file = f\"/Users/guptatilak/Documents/C4GT-Face-Recognition/Testing/outputs/test/{model_name}_{detector_backend}_{distance_metric}_{align}.csv\"\n",
    "    # source_file = '/Users/guptatilak/Documents/C4GT-Face-Recognition/Dlib_retinaface_cosine_aligned.csv'\n",
    "\n",
    "    if not os.path.exists(source_file):\n",
    "        print(f\"Source file {source_file} does not exist. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(source_file)\n",
    "    \n",
    "    # Check if a custom threshold exists for the current model configuration\n",
    "    if (model_name, detector_backend) not in custom_thresholds:\n",
    "        print(f\"No custom threshold for {model_name} with {detector_backend}. Skipping...\")\n",
    "        continue\n",
    "    \n",
    "    threshold = custom_thresholds[(model_name, detector_backend)]\n",
    "\n",
    "    sandbox_df = df.copy()\n",
    "    sandbox_df[\"predictions\"] = False\n",
    "    idx = sandbox_df[sandbox_df[\"distances\"] < threshold].index\n",
    "    sandbox_df.loc[idx, \"predictions\"] = True\n",
    "\n",
    "    actuals = sandbox_df.actuals.values.tolist()\n",
    "    predictions = sandbox_df.predictions.values.tolist()\n",
    "    accuracy = 100 * accuracy_score(actuals, predictions)\n",
    "\n",
    "    # Add the accuracy to the result dataframe\n",
    "    data_to_append = {\n",
    "        'model_name': model_name,\n",
    "        'detector_backend': detector_backend,\n",
    "        'distance_metric': distance_metric,\n",
    "        'alignment': 'TRUE' if align == 'aligned' else 'FALSE',\n",
    "        'threshold': threshold,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "\n",
    "    result = result.append(data_to_append, ignore_index=True)\n",
    "    print(f\"Threshold for {model_name} with {detector_backend} and alignment {'TRUE' if align == 'aligned' else 'FALSE'} is {threshold} with accuracy {accuracy}\")\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>detector_backend</th>\n",
       "      <th>distance_metric</th>\n",
       "      <th>alignment</th>\n",
       "      <th>threshold</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dlib</td>\n",
       "      <td>retinaface</td>\n",
       "      <td>cosine</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>0.06</td>\n",
       "      <td>94.864589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name detector_backend distance_metric alignment threshold   accuracy\n",
       "0       Dlib       retinaface          cosine      TRUE      0.06  94.864589"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/Users/guptatilak/Documents/C4GT-Face-Recognition/offline-FR/faceboxes-edgeface-FR/threshold/outputs/edgeface_faceboxes_cosine_unaligned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actuals</th>\n",
       "      <th>distances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.989668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.942854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.877299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.671457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.819048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1</td>\n",
       "      <td>0.991342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1</td>\n",
       "      <td>0.341092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1</td>\n",
       "      <td>0.996671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1</td>\n",
       "      <td>0.658942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>0.174880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     actuals  distances\n",
       "0          1   0.989668\n",
       "1          0   0.942854\n",
       "2          1   0.877299\n",
       "3          0   0.671457\n",
       "4          0   0.819048\n",
       "..       ...        ...\n",
       "392        1   0.991342\n",
       "393        1   0.341092\n",
       "394        1   0.996671\n",
       "395        1   0.658942\n",
       "396        0   0.174880\n",
       "\n",
       "[397 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_mean = round(df[df.actuals == 1].mean().values[1], 4)\n",
    "tp_std = round(df[df.actuals == 1].std().values[1], 4)\n",
    "fp_mean = round(df[df.actuals == 0].mean().values[1], 4)\n",
    "fp_std = round(df[df.actuals == 0].std().values[1], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "matplotlib is required for plotting when the default backend \"matplotlib\" is selected.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactuals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistances\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkde\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df[df\u001b[38;5;241m.\u001b[39mactuals \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdistances\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mkde()\n",
      "File \u001b[0;32m~/Documents/C4GT-Face-Recognition/offline-FR/faceboxes-edgeface-FR/myenv/lib/python3.10/site-packages/pandas/plotting/_core.py:1482\u001b[0m, in \u001b[0;36mPlotAccessor.kde\u001b[0;34m(self, bw_method, ind, **kwargs)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkde\u001b[39m(\u001b[38;5;28mself\u001b[39m, bw_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ind\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PlotAccessor:\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;124;03m    Generate Kernel Density Estimate plot using Gaussian kernels.\u001b[39;00m\n\u001b[1;32m   1379\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[38;5;124;03m        >>> ax = df.plot.kde(ind=[1, 2, 3, 4, 5, 6])\u001b[39;00m\n\u001b[1;32m   1481\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkde\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbw_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbw_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/C4GT-Face-Recognition/offline-FR/faceboxes-edgeface-FR/myenv/lib/python3.10/site-packages/pandas/plotting/_core.py:920\u001b[0m, in \u001b[0;36mPlotAccessor.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 920\u001b[0m     plot_backend \u001b[38;5;241m=\u001b[39m \u001b[43m_get_plot_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbackend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    922\u001b[0m     x, y, kind, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_call_args(\n\u001b[1;32m    923\u001b[0m         plot_backend\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent, args, kwargs\n\u001b[1;32m    924\u001b[0m     )\n\u001b[1;32m    926\u001b[0m     kind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kind_aliases\u001b[38;5;241m.\u001b[39mget(kind, kind)\n",
      "File \u001b[0;32m~/Documents/C4GT-Face-Recognition/offline-FR/faceboxes-edgeface-FR/myenv/lib/python3.10/site-packages/pandas/plotting/_core.py:1886\u001b[0m, in \u001b[0;36m_get_plot_backend\u001b[0;34m(backend)\u001b[0m\n\u001b[1;32m   1883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend_str \u001b[38;5;129;01min\u001b[39;00m _backends:\n\u001b[1;32m   1884\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _backends[backend_str]\n\u001b[0;32m-> 1886\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43m_load_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1887\u001b[0m _backends[backend_str] \u001b[38;5;241m=\u001b[39m module\n\u001b[1;32m   1888\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\n",
      "File \u001b[0;32m~/Documents/C4GT-Face-Recognition/offline-FR/faceboxes-edgeface-FR/myenv/lib/python3.10/site-packages/pandas/plotting/_core.py:1817\u001b[0m, in \u001b[0;36m_load_backend\u001b[0;34m(backend)\u001b[0m\n\u001b[1;32m   1815\u001b[0m         module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.plotting._matplotlib\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1816\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m-> 1817\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m   1818\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatplotlib is required for plotting when the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1819\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault backend \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is selected.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1820\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1821\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m module\n\u001b[1;32m   1823\u001b[0m found_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: matplotlib is required for plotting when the default backend \"matplotlib\" is selected."
     ]
    }
   ],
   "source": [
    "df[df.actuals == 1].distances.plot.kde()\n",
    "df[df.actuals == 0].distances.plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2287"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Statistical Approach\n",
    "sigma = 2\n",
    "threshold = round(tp_mean + sigma * tp_std, 4)\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chefboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import the Chefboost library\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchefboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Chefboost \u001b[38;5;28;01mas\u001b[39;00m chef\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Configuration for the C4.5 algorithm\u001b[39;00m\n\u001b[1;32m      5\u001b[0m config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malgorithm\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC4.5\u001b[39m\u001b[38;5;124m'\u001b[39m}\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'chefboost'"
     ]
    }
   ],
   "source": [
    "# Import the Chefboost library\n",
    "from chefboost import Chefboost as chef\n",
    "\n",
    "# Configuration for the C4.5 algorithm\n",
    "config = {'algorithm': 'C4.5'}\n",
    "\n",
    "# Print the column names of the DataFrame to verify\n",
    "print(df.columns)\n",
    "\n",
    "# Ensure the column names are correct\n",
    "if 'actuals' in df.columns and 'distances' in df.columns:\n",
    "    # Preparing the data\n",
    "    tmp_df = df[['actuals', 'distances']].rename(columns={\"actuals\": \"Decision\"}).copy()\n",
    "    tmp_df['Decision'] = tmp_df['Decision'].astype(str)  # Convert decision column to string type\n",
    "    \n",
    "    # Fit the model\n",
    "    model = chef.fit(tmp_df, config)\n",
    "\n",
    "    # After fitting, Chefboost will output the decision tree.\n",
    "    # You need to manually inspect the printed tree to find the threshold.\n",
    "else:\n",
    "    print(\"Error: The DataFrame does not contain the required columns 'actuals' and 'distances'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
